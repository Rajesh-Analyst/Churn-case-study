{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WeVM3bNw1aq"
   },
   "source": [
    "# Telecom Churn - Case Study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem Overview\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    " \n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business goal.\n",
    " \n",
    " \n",
    "\n",
    "To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.\n",
    "\n",
    " \n",
    "\n",
    "In this project, you will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VghQ7YBw1as"
   },
   "source": [
    "### business objective:\n",
    "The business objective is to predict the churn in the last (i.e. the ninth) month using the data (features) from the first three months. To do this task well, understanding the typical customer behaviour during churn will be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvPhyxKZw1az"
   },
   "outputs": [],
   "source": [
    "# Ignoring warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import library\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns',230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2roMMJbw1a6",
    "outputId": "ac71a6eb-4be3-465e-f301-9dabcbd9bc9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acronyms</th>\n",
       "      <th>Descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOBILE_NUMBER</td>\n",
       "      <td>Customer phone number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIRCLE_ID</td>\n",
       "      <td>Telecom circle area to which the customer belo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Local calls - within same telecom circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STD</td>\n",
       "      <td>STD calls - outside the calling circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IC</td>\n",
       "      <td>Incoming calls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Acronyms                                           Descriptions\n",
       "0  MOBILE_NUMBER                              Customer phone number\n",
       "1      CIRCLE_ID  Telecom circle area to which the customer belo...\n",
       "2            LOC           Local calls - within same telecom circle\n",
       "3            STD             STD calls - outside the calling circle\n",
       "4             IC                                     Incoming calls"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "#file_path =\"telecom_churn_data..xlsx\"\n",
    "#churn = pd.read_csv(file_path)\n",
    "churn= pd.read_csv('telecom_churn_data.csv')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 2)\n"
     ]
    }
   ],
   "source": [
    "print(churn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Acronyms      38 non-null     object\n",
      " 1   Descriptions  38 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 736.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(churn.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thaqLR4ww1bF",
    "outputId": "f1fefc3a-db74-4355-c1bd-bc9022fa1af4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acronyms</th>\n",
       "      <th>Descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>SACHET</td>\n",
       "      <td>KPI for the month of August</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Acronyms                     Descriptions\n",
       "count            38                           38\n",
       "unique           38                           38\n",
       "top       SACHET     KPI for the month of August\n",
       "freq              1                            1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSFhG0VQw1bO",
    "outputId": "eba5db71-2be3-4c6c-ac0f-768987f58437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cutomer-level information for each customer is represented by 2 features\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'MOBILE_NUMBER'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cc65566e3767>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"The cutomer-level information for each customer is represented by %d features\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# getting unique number of custormers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Unique customers/MSISDN in the data: %d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMOBILE_NUMBER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'MOBILE_NUMBER'"
     ]
    }
   ],
   "source": [
    "print (\"The cutomer-level information for each customer is represented by %d features\"% (churn.shape[1]))\n",
    "# getting unique number of custormers\n",
    "print (\"Unique customers/MSISDN in the data: %d\"%len(churn.MOBILE_NUMBER.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfKES94-w1bT",
    "outputId": "bf5788b2-e604-4c1c-daa6-a54d3675676c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acronyms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Descriptions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0  Acronyms    \n",
       "1  Descriptions"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of columns\n",
    "pd.DataFrame(churn.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IyfWdSy4w1bZ"
   },
   "source": [
    "##  Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgfFK9pzw1ba"
   },
   "source": [
    "Custome function Defination for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-w7VwT9Sw1bd"
   },
   "outputs": [],
   "source": [
    "def getMissingValues(missingCutoff):\n",
    "    # Function to retun the columns with more than missingCutoff% missing values.\n",
    "    # argument: missingCutoff, % values threshold for missing values\n",
    "    missing = round(100*(churn.isnull().sum()/churn.shape[0]))\n",
    "    print(\"There are {} features having more than {}% missing values/entries\".format(len(missing.loc[missing > missingCutoff]),missingCutoff))\n",
    "    return missing.loc[missing > missingCutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpKT6Evow1bg"
   },
   "outputs": [],
   "source": [
    "def imputeNan(data,imputeColList=False,missingColList=False):\n",
    "    # Function impute the nan with 0\n",
    "    # argument: colList, list of columns for which nan is to be replaced with 0\n",
    "    if imputeColList:\n",
    "        for col in [y + s for s in ['_6','_7','_8','_9'] for y in imputeColList]:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "    else:    \n",
    "        for col in missingColList:\n",
    "            data[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_YDMY8Dw1bj"
   },
   "source": [
    "##### Handling missing data\n",
    "Let's check for missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKonDVuKw1bk",
    "outputId": "f8c6a5f2-13ca-4bc3-d6f9-f2589ddab768",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 features having more than 50% missing values/entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values per column expressed as % of total number of values\n",
    "getMissingValues(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-lu8wY4w1bq"
   },
   "source": [
    "Out the these 40 features, many are required and are essential for analysis. The missing values for these features seems to suggest that these customers KPI's did not have any value at that month. We can choose to impute these values with 0 to make enable these features to give value to analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qHQktPDgw1br"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'av_rech_amt_data_6'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'av_rech_amt_data_6'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f8f5f02e3f0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m imputeCol = ['av_rech_amt_data', 'arpu_2g', 'arpu_3g', 'count_rech_2g', 'count_rech_3g',\n\u001b[0;32m      4\u001b[0m              'max_rech_data', 'total_rech_data','fb_user','night_pck_user']\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimputeNan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimputeCol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-dc070d261319>\u001b[0m in \u001b[0;36mimputeNan\u001b[1;34m(data, imputeColList, missingColList)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mimputeColList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'_6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_9'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimputeColList\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissingColList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'av_rech_amt_data_6'"
     ]
    }
   ],
   "source": [
    "# Since av_rech_amt_data_* features are important for getting the high-value customers,\n",
    "#lets impute the missing av_rech_amt_data_* with 0\n",
    "imputeCol = ['av_rech_amt_data', 'arpu_2g', 'arpu_3g', 'count_rech_2g', 'count_rech_3g',\n",
    "             'max_rech_data', 'total_rech_data','fb_user','night_pck_user']\n",
    "imputeNan(churn,imputeCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4b7vA2Fcw1bu",
    "outputId": "7479dd37-701b-445d-c0f3-9914d29134ee"
   },
   "outputs": [],
   "source": [
    "getMissingValues(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgznSmO-w1bz",
    "outputId": "26e405da-2af4-4b2b-cabd-646b3eb8c696"
   },
   "outputs": [],
   "source": [
    "# dropping the columns having more than 50% missing values\n",
    "missingcol = list(getMissingValues(50).index)\n",
    "churn.drop(missingcol,axis=1,inplace=True)\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVbTUyRUw1b7",
    "outputId": "f449d7bc-4c9d-4943-b39c-063dc0bb73d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing values per column expressed as % of total number of values > 5%\n",
    "getMissingValues(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AymtxYWMw1cD"
   },
   "source": [
    "Looks like all these features for the month sep(9) are missing together. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSWl9fQrw1cG",
    "outputId": "8ebac937-5cd3-44d4-8b2f-a9f0757c19a2"
   },
   "outputs": [],
   "source": [
    "# checking if all these above features go missing together since they have the same 8% missing values in each feature.\n",
    "missingcol = list(getMissingValues(5).index)\n",
    "print (\"There are %d customers/MSISDN's having missing values for %s together\"%(len(churn[churn[missingcol].isnull().all(axis=1)]),missingcol))\n",
    "churn[churn[missingcol].isnull().all(axis=1)][missingcol].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPK0k-Cpw1cU"
   },
   "source": [
    "Yes, It looks like for **7745 Customers** all these features are empty together without any value. We can choose to impute these values with 0 also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0lN0Ocbw1cV"
   },
   "outputs": [],
   "source": [
    "imputeNan(churn,missingColList=missingcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ze7632LVw1cZ",
    "outputId": "348e34ba-7e49-4d77-a4eb-bea939cd7a2e"
   },
   "outputs": [],
   "source": [
    "churn=churn[~churn[missingcol].isnull().all(axis=1)]\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8ngtLTTw1ce",
    "outputId": "ce447628-b276-46bf-8065-1f70eb624cf6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing values per column expressed as % of total number of values\n",
    "getMissingValues(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTKMYsOsw1ch",
    "outputId": "678f832d-545e-43b1-ec31-93211f8b684d"
   },
   "outputs": [],
   "source": [
    "missingcol = list(getMissingValues(2).index)\n",
    "print (\"There are %d customers/MSISDN's having missing values for %s together\"%(len(churn[churn[missingcol].isnull().all(axis=1)]),missingcol))\n",
    "churn[churn[missingcol].isnull().all(axis=1)][missingcol].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sh09uXj9w1cj"
   },
   "source": [
    "Yes, It looks like there are **381 Customers** for whom **all** these features are without any value.\n",
    "Let's drop these customers from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2SB9HcIw1ck",
    "outputId": "ebeb1559-942d-476c-d38e-9f49a4987b28"
   },
   "outputs": [],
   "source": [
    "churn=churn[~churn[missingcol].isnull().all(axis=1)]\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NACoOfVTw1co"
   },
   "outputs": [],
   "source": [
    "# For other customers where these missing values are spread out, let's impute them with zero. \n",
    "\n",
    "missingcol.remove('date_of_last_rech_8')\n",
    "missingcol.remove('date_of_last_rech_9')\n",
    "imputeNan(churn,missingColList=missingcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrHn6DAxw1cp",
    "outputId": "67adf5b3-58e7-4092-adb2-5064e43dba6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing values per column expressed as % of total number of values\n",
    "getMissingValues(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGM8cLz7w1cs",
    "outputId": "e1ac84d7-e26d-43b4-99d5-701f73a92d61"
   },
   "outputs": [],
   "source": [
    "col = ['loc_og_t2o_mou','std_og_t2o_mou','loc_ic_t2o_mou','last_date_of_month_7','last_date_of_month_8','last_date_of_month_9', 'date_of_last_rech_7', 'date_of_last_rech_8', 'date_of_last_rech_9']\n",
    "for c in col: \n",
    "    print(\"Unique values in column %s are %s\" % (c,churn[c].unique()))\n",
    "                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2oIZ0SAw1cu",
    "outputId": "b54c38be-4ad0-431b-a358-874b29db8558"
   },
   "outputs": [],
   "source": [
    "#Some of these features take only one value. Lets impute their missing values in these features with the mode\n",
    "col = ['loc_og_t2o_mou','std_og_t2o_mou','loc_ic_t2o_mou','last_date_of_month_7','last_date_of_month_8','last_date_of_month_9']\n",
    "for c in col:\n",
    "    print(churn[c].value_counts())\n",
    "    churn[c].fillna(churn[c].mode()[0], inplace=True)\n",
    "print(\"All the above features take only one value. Lets impute the missing values in these features with the mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjx6oo2Yw1cy",
    "outputId": "27518364-ca39-401d-e492-afc85ce665c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing values per column expressed as % of total number of values\n",
    "getMissingValues(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VALyQ_Flw1c0",
    "outputId": "69cf94b5-ba30-4ea6-a059-99fb8b11432c"
   },
   "outputs": [],
   "source": [
    "# All these features are missing together\n",
    "missingcol = list(getMissingValues(0).index)\n",
    "print (\"There are %d rows in total having missing values for these variables.\"%(len(churn[churn[missingcol].isnull().all(axis=1)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvljWLqHw1c3"
   },
   "outputs": [],
   "source": [
    "churn[churn['date_of_last_rech_6'].isnull()]['date_of_last_rech_6'] = '6/30/2014'\n",
    "churn[churn['date_of_last_rech_7'].isnull()]['date_of_last_rech_7'] = '7/31/2014'\n",
    "churn[churn['date_of_last_rech_8'].isnull()]['date_of_last_rech_8'] = '8/31/2014'\n",
    "churn[churn['date_of_last_rech_9'].isnull()]['date_of_last_rech_9'] = '9/30/2014'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctJ4Mw_8w1c5"
   },
   "source": [
    "<br><br>Let's look for columns having all values as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vz2OPtSaw1c6",
    "outputId": "a3f86eef-ff61-492d-e8ae-b46eec0edd8b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zero_columns=churn.columns[(churn == 0).all()]\n",
    "print (\"There are {} features which has only 0 as values. These features are \\n{}\".format(len(zero_columns),zero_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQWFI3V7w1c9"
   },
   "outputs": [],
   "source": [
    "# Let's remove these columns as well. All take a single value '0'. \n",
    "churn.drop(zero_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RIOWKmcw1c-",
    "outputId": "6bc3abf4-6c90-49a6-cd37-02b4235e1bbb"
   },
   "outputs": [],
   "source": [
    "# Percentage of data left after removing the missing values.\n",
    "print(\"Percentage of data remaining after treating missing values: {}%\".format(round(churn.shape[0]/99999 *100,2)))\n",
    "print (\"Number of customers: {}\".format(churn.shape[0]))\n",
    "print (\"Number of features: {}\".format(churn.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjw-a_hEw1dB"
   },
   "source": [
    "##### Fixing data types and columns names\n",
    "\n",
    "Let's check for data types of the different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ETZnE1_w1dD",
    "outputId": "d4abac5e-2576-4f43-9190-8ee49448704c"
   },
   "outputs": [],
   "source": [
    "churn.reset_index(inplace=True,drop=True)\n",
    "# list of all columns which store date\n",
    "date_columns = list(churn.filter(regex='date').columns)\n",
    "date_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuClA7HUw1dF"
   },
   "outputs": [],
   "source": [
    "# Converting dtype of date columns to datetime\n",
    "for col in date_columns:\n",
    "    churn[col] = pd.to_datetime(churn[col], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54YP75GUw1dH",
    "outputId": "66008bd4-5815-4b5b-825f-44445c8e2889"
   },
   "outputs": [],
   "source": [
    "churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzhtu1KKw1dL"
   },
   "source": [
    "<br><br> There are some monthly features which are not in the standard naming (\\_6,\\_7,\\_8,\\_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cN2FCQ0iw1dN"
   },
   "outputs": [],
   "source": [
    "# renaming columns,\n",
    "#'jun_vbc_3g' : 'vbc_3g_6'\n",
    "#'jul_vbc_3g' : 'vbc_3g_7'\n",
    "#'aug_vbc_3g' : 'vbc_3g_8'\n",
    "#'sep_vbc_3g' : 'vbc_3g_9'\n",
    "churn.rename(columns={'jun_vbc_3g' : 'vbc_3g_6', 'jul_vbc_3g' : 'vbc_3g_7', 'aug_vbc_3g' : 'vbc_3g_8',\n",
    "                      'sep_vbc_3g' : 'vbc_3g_9'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0pyAEUgqw1dS"
   },
   "source": [
    "**Creating new feature:** 'vol_data_mb_6', 'vol_data_mb_7', 'vol_data_mb_8', 'vol_data_mb_9'\n",
    "\n",
    "These will store the total data volume (= vol_2g_mb_* + vol_3g_mb_*) used by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rg_rkfalw1dT"
   },
   "outputs": [],
   "source": [
    "#Creating new feature: 'vol_data_mb_6', 'vol_data_mb_7', 'vol_data_mb_8', 'vol_data_mb_9',\n",
    "for i in range(6,10):\n",
    "    churn['vol_data_mb_'+str(i)] = (churn['vol_2g_mb_'+str(i)]+churn['vol_3g_mb_'+str(i)]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrjIoPLqw1dV"
   },
   "source": [
    "###### Filter high-value customers\n",
    "Defining high-value customers as follows: \n",
    "\n",
    "Those who have recharged with an amount more than or equal to X, where X is the 70th percentile of the average recharge amount in the first two months (the good phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s48O0Cchw1dW",
    "outputId": "d928f40c-f839-4874-c815-ee65db769918"
   },
   "outputs": [],
   "source": [
    "rechcol = churn.filter(regex=('count')).columns\n",
    "churn[rechcol].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OYxyezxw1da"
   },
   "source": [
    "**Creating new feature:** avg_rech_amt_6,avg_rech_amt_7,avg_rech_amt_8,avg_rech_amt_9\n",
    "\n",
    "These will store the average recharge value for each customer for every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SrlH8Cktw1db"
   },
   "outputs": [],
   "source": [
    "# Creating new feature: avg_rech_amt_6,avg_rech_amt_7,avg_rech_amt_8,avg_rech_amt_9\n",
    "for i in range(6,10):\n",
    "    churn['avg_rech_amt_'+str(i)] = round(churn['total_rech_amt_'+str(i)]/churn['total_rech_num_'+str(i)]+1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5N3thOfow1de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputeNan(churn,missingColList=['avg_rech_amt_6','avg_rech_amt_7','avg_rech_amt_8','avg_rech_amt_9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SnL_dQ01w1df"
   },
   "source": [
    "**Creating new feature:** total_rech_num_data_6,total_rech_num_data_7,total_rech_num_data_8,total_rech_num_data_9\n",
    "\n",
    "These will store the total number of data recharge (=count_rech_2g + count_rech_3g ) for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emHL6dAMw1dg"
   },
   "outputs": [],
   "source": [
    "#Creating new feature: total_rech_num_data_6,total_rech_num_data_7,total_rech_num_data_8,total_rech_num_data_9\n",
    "for i in range(6,10):\n",
    "    churn['total_rech_num_data_'+str(i)] = (churn['count_rech_2g_'+str(i)]+churn['count_rech_3g_'+str(i)]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OocpanW-w1di"
   },
   "source": [
    "**Creating new feature:** total_rech_amt_data_6,total_rech_amt_data_7,total_rech_amt_data_8,total_rech_amt_data_9\n",
    "\n",
    "These will store the total amount of data recharge (=total_rech_num_data * av_rech_amt_data ) for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rX-9PquQw1dj"
   },
   "outputs": [],
   "source": [
    "#Creating new feature: total_rech_amt_data_6,total_rech_amt_data_7,total_rech_amt_data_8,total_rech_amt_data_9\n",
    "for i in range(6,10):\n",
    "    churn['total_rech_amt_data_'+str(i)] = churn['total_rech_num_data_'+str(i)]*churn['av_rech_amt_data_'+str(i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQ3LlH7_w1dk"
   },
   "source": [
    "**Creating new feature:** total_month_rech_6,total_month_rech_7,total_month_rech_8,total_month_rech_9\n",
    "\n",
    "These will store the total recharge amount (= total_rech_amt + total_rech_amt_data ) for each customer, for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgZIynXMw1dm",
    "outputId": "1f52cdee-6c2d-4d89-ddb6-d1c73e6cd72a"
   },
   "outputs": [],
   "source": [
    "#Creating new feature: total_mon_rech_6,total_mon_rech_7,total_mon_rech_8,total_mon_rech_9\n",
    "for i in range(6,10):\n",
    "    churn['total_month_rech_'+str(i)] = churn['total_rech_amt_'+str(i)]+churn['total_rech_amt_data_'+str(i)]\n",
    "churn.filter(regex=('total_month_rech')).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SXsOuKsw1dp",
    "outputId": "32ab1994-0eef-4104-a3e3-d67af23e7adf"
   },
   "outputs": [],
   "source": [
    "# calculating the avegare of first two months (good phase) total monthly recharge amount\n",
    "avg_goodPhase =(churn.total_month_rech_6 + churn.total_month_rech_7)/2\n",
    "# finding the cutoff which is the 70th percentile of the good phase average recharge amounts\n",
    "hv_cutoff= np.percentile(avg_goodPhase,70)\n",
    "# Filtering the users whose good phase avg. recharge amount >= to the cutoff of 70th percentile.\n",
    "hv_users = churn[avg_goodPhase >=  hv_cutoff]\n",
    "hv_users.reset_index(inplace=True,drop=True)\n",
    "\n",
    "print(\"Number of High-Value Customers in the Dataset: %d\\n\"% len(hv_users))\n",
    "print(\"Percentage High-value users in data : {}%\".format(round(len(hv_users)/churn.shape[0]*100),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNPxDUQ7w1ds"
   },
   "source": [
    "###### Tagging Churners\n",
    "Now tag the churned customers (churn=1, else 0) based on the fourth month as follows:\n",
    "\n",
    "Those who have not made any calls (either incoming or outgoing) AND have not used mobile internet even once in the churn phase. The attributes we need to use to tag churners are:\n",
    "- total_ic_mou_9\n",
    "- total_og_mou_9\n",
    "- vol_2g_mb_9\n",
    "- vol_3g_mb_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhHhvVILw1du"
   },
   "outputs": [],
   "source": [
    "def getChurnStatus(data,churnPhaseMonth=9):\n",
    "    # Function to tag customers as churners (churn=1, else 0) based on 'vol_2g_mb_','vol_3g_mb_','total_ic_mou_','total_og_mou_'\n",
    "    #argument: churnPhaseMonth, indicating the month number to be used to define churn (default= 9)\n",
    "    churn_features= ['vol_2g_mb_','vol_3g_mb_','total_ic_mou_','total_og_mou_']\n",
    "    flag = ~data[[s + str(churnPhaseMonth) for s in churn_features ]].any(axis=1)\n",
    "    flag = flag.map({True:1, False:0})\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0diq7zy2w1dx",
    "outputId": "41032039-62bb-4f8a-e4aa-0243b3ae7ebe"
   },
   "outputs": [],
   "source": [
    "hv_users['churn'] = getChurnStatus(hv_users,9)\n",
    "print(\"There are {} users tagged as churners out of {} High-Value Customers.\".format(len(hv_users[hv_users.churn == 1]),hv_users.shape[0]))\n",
    "print(\"High-value Churn Percentage : {}%\".format(round(len(hv_users[hv_users.churn == 1])/hv_users.shape[0] *100,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLsZKd11w1dz"
   },
   "source": [
    "<br>There are just **8.09% churn** cases.\n",
    "<br>This indicated an **highly imbalanced** data set where the churn cases are the minority(8.14%) as opposed to the non-churners who are the majority(91.91)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFQpGLvaw1d0"
   },
   "source": [
    "---\n",
    "##  Data Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQKORwbXw1d1"
   },
   "source": [
    "Define few methods to aid in plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjdRs2oYw1d1"
   },
   "outputs": [],
   "source": [
    "# Function to plot the histogram with labels\n",
    "# https://stackoverflow.com/questions/6352740/matplotlib-label-each-bin\n",
    "def plot_hist(dataset,col,binsize):\n",
    "    fig, ax = plt.subplots(figsize=(20,4))\n",
    "    counts, bins, patches = ax.hist(dataset[col],bins=range(0,dataset[col].max(),round(binsize)), facecolor='lightgreen', edgecolor='gray')\n",
    "    \n",
    "    # Set the ticks to be at the edges of the bins.\n",
    "    ax.set_xticks(bins)\n",
    "    bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "    for count, x in zip(counts, bin_centers):\n",
    "        # Label the percentages\n",
    "        percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "        ax.annotate(percent, xy=(x,0.2), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    ax.set_xlabel(col.upper())\n",
    "    ax.set_ylabel('Count')\n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "    #plt.subplots_adjust(bottom=0.15)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9TdcYbRw1d3"
   },
   "outputs": [],
   "source": [
    "def plot_avgMonthlyCalls(pltType,data,calltype,colList):\n",
    "    # style\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    # create a color palette\n",
    "    palette = plt.get_cmap('Set1')\n",
    "    \n",
    "    if pltType == 'multi':\n",
    "        #Create dataframe after grouping on AON with colList features\n",
    "        total_call_mou = pd.DataFrame(data.groupby('aon_bin',as_index=False)[colList].mean())\n",
    "        total_call_mou['aon_bin']=pd.to_numeric(total_call_mou['aon_bin'])\n",
    "        total_call_mou\n",
    "        # multiple line plot\n",
    "        num=0\n",
    "        fig, ax = plt.subplots(figsize=(15,8))\n",
    "        for column in total_call_mou.drop('aon_bin', axis=1):\n",
    "            num+=1\n",
    "            ax.plot(total_call_mou['aon_bin'] , total_call_mou[column], marker='', color=palette(num), linewidth=2, alpha=0.9, label=column)\n",
    "         \n",
    "        ## Add legend\n",
    "        plt.legend(loc=2, ncol=2)\n",
    "        ax.set_xticks(total_call_mou['aon_bin'])\n",
    "        \n",
    "        # Add titles\n",
    "        plt.title(\"Avg.Monthly \"+calltype+\" MOU  V/S AON\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "        plt.xlabel(\"Aon (years)\")\n",
    "        plt.ylabel(\"Avg. Monthly \"+calltype+\" MOU\")\n",
    "    elif pltType == 'single':\n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        ax.plot(data[colList].mean())\n",
    "        ax.set_xticklabels(['Jun','Jul','Aug','Sep'])\n",
    "        \n",
    "        # Add titles\n",
    "        plt.title(\"Avg. \"+calltype+\" MOU  V/S Month\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "        plt.xlabel(\"Month\")\n",
    "        plt.ylabel(\"Avg. \"+calltype+\" MOU\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLOa5t68w1d5"
   },
   "outputs": [],
   "source": [
    "def plot_byChurnMou(colList,calltype):\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    df=hv_users.groupby(['churn'])[colList].mean().T\n",
    "    plt.plot(df)\n",
    "    ax.set_xticklabels(['Jun','Jul','Aug','Sep'])\n",
    "    ## Add legend\n",
    "    plt.legend(['Non-Churn', 'Churn'])\n",
    "    # Add titles\n",
    "    plt.title(\"Avg. \"+calltype+\" MOU  V/S Month\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Avg. \"+calltype+\" MOU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8gag9qdw1d6"
   },
   "outputs": [],
   "source": [
    "def plot_byChurn(data,col):\n",
    "    # per month churn vs Non-Churn\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    colList=list(data.filter(regex=(col)).columns)\n",
    "    colList = colList[:3]\n",
    "    plt.plot(hv_users.groupby('churn')[colList].mean().T)\n",
    "    ax.set_xticklabels(['Jun','Jul','Aug','Sep'])\n",
    "    ## Add legend\n",
    "    plt.legend(['Non-Churn', 'Churn'])\n",
    "    # Add titles\n",
    "    plt.title( str(col) +\" V/S Month\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(col)\n",
    "    plt.show()\n",
    "    # Numeric stats for per month churn vs Non-Churn\n",
    "    return hv_users.groupby('churn')[colList].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxYP-q7Sw1d8",
    "outputId": "e917d710-5969-43bf-bcd2-cd0e58cdd8db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering the common monthly columns for each month\n",
    "comcol = hv_users.filter(regex ='_6').columns\n",
    "monthlycol = [item.strip('_6') for item in comcol]\n",
    "monthlycol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWH3yH1Iw1d-",
    "outputId": "23f5d9c1-8b3d-4881-a790-c7b8f5b1f968",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getting the number of monthly columns and profile columns\n",
    "print (\"Total number of columns in data :\", hv_users.shape[1] )\n",
    "print (\"Number of columns for each month : \",len(monthlycol))\n",
    "print (\"Total monthly columns among the orignal columns (%d*4): %d\"%(len(monthlycol), len(monthlycol) * 4))\n",
    "print (\"Columns other than monthly columns :\", hv_users.shape[1] - (len(monthlycol) * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8h7FoRMzw1eB"
   },
   "outputs": [],
   "source": [
    "# Lets remove all the attributes corresponding to the churn phase (all attributes having  _9, etc. in their names).\n",
    "col_9List = hv_users.filter(regex=('_9')).columns\n",
    "hv_users.drop(col_9List,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0J7mTEYw1eF",
    "outputId": "37c73aca-a4b7-459d-d016-72cdc0c53b63",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list of all the monthly columns 6,7,8,9\n",
    "allmonthlycol = [x + s for s in ['_6','_7','_8'] for x in monthlycol]\n",
    "allmonthlycol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKXiNmSbw1eH",
    "outputId": "08e883eb-4ef4-496d-e7bc-f328eb32b679"
   },
   "outputs": [],
   "source": [
    "# list of column which are not monthly columns\n",
    "nonmonthlycol = [col for col in hv_users.columns if col not in allmonthlycol]\n",
    "nonmonthlycol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YQFLTeVw1eK"
   },
   "source": [
    "###### Feature: circle_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RY0OWTDLw1eK",
    "outputId": "69eaad65-a1b4-4561-fcc0-ba1339d8e311"
   },
   "outputs": [],
   "source": [
    "# Getting the distinct circle_id's in the data\n",
    "hv_users.circle_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_1PgbT4w1eN"
   },
   "source": [
    "Looks like the data at hand is only for a single **circle_id 109.** <br>We can remove this feature going forward as it is not contributing to analysis and model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ag1zWjQFw1eN"
   },
   "outputs": [],
   "source": [
    "hv_users.drop('circle_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f73KSgqJw1eP"
   },
   "source": [
    "###### Feature: aon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qVLacWZw1eR",
    "outputId": "41181225-eba8-4b50-e659-af312bcb536d"
   },
   "outputs": [],
   "source": [
    "# Customers distribution of the age on network\n",
    "print(hv_users.aon.describe())\n",
    "plot_hist(hv_users,'aon',365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOgSziUgw1eU"
   },
   "source": [
    "- **Minimun Age** on network is 180 days.\n",
    "- **Average age** on network for customers is 1200 days (3.2 years).\n",
    "- 27% of the **HV users are in their 2nd year** with the network.\n",
    "- Almost 71% users have Age on network **less than 4 years.**\n",
    "- 15% users are with the network from **over 7 years.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlWZlssNw1eV"
   },
   "outputs": [],
   "source": [
    "#Create Derived categorical variable\n",
    "hv_users['aon_bin'] = pd.cut(churn['aon'], range(0,churn['aon'].max(),365), labels=range(0,int(round(churn['aon'].max()/365))-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwaq2WOww1eW"
   },
   "source": [
    "###### Incoming VS month VS AON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUHlpHBZw1eX",
    "outputId": "9937fe97-1833-4dfb-dda4-6007f4e43dc4"
   },
   "outputs": [],
   "source": [
    "# Plotting Avg. total monthly incoming MOU vs AON\n",
    "ic_col = hv_users.filter(regex ='total_ic_mou').columns\n",
    "plot_avgMonthlyCalls('single',hv_users,calltype='incoming',colList=ic_col)\n",
    "plot_avgMonthlyCalls('multi',hv_users,calltype='incoming',colList=ic_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxzrjh6Kw1ea"
   },
   "source": [
    "It is evident from the plot that,\n",
    "- The more a customer stays on with the operator(AON), more are the total monthly incoming MOU.\n",
    "- Total Incoming MOU avg. for Jul(_7) are more than the previous Jun(_6) for customers in all AON bands.\n",
    "- Total Incoming MOU avg. for Aug(_8) cease to increace, infact it shows a decline compared to Jul(_7).\n",
    "- Total Incoming MOU avg. for Sep(_9) is well below the first months(jun _6) avg.\n",
    "- Althought the Total incoming mou avg inceases from jun to july, it drop little from aug and reduces lower than that for jun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wl5pKN48w1ea"
   },
   "source": [
    "###### Outgoing VS month VS AON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUszJkD2w1eb",
    "outputId": "e1e00cae-5cc3-4e17-f499-03dd735fe988"
   },
   "outputs": [],
   "source": [
    "# Plotting Avg. total monthly outgoing MOU vs AON\n",
    "og_col = hv_users.filter(regex ='total_og_mou').columns\n",
    "plot_avgMonthlyCalls('single',hv_users,calltype='outgoing',colList=og_col)\n",
    "plot_avgMonthlyCalls('multi',hv_users,calltype='outgoing',colList=og_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxpn3xexw1ed"
   },
   "source": [
    "What is the above plot saying ?\n",
    "- Overall, the Avg. total outgoing usage reduces with the increasing age on network.\n",
    "- Total Outgoing MOU avg. for Jul(_7) are more than the previous Jun(_6) for customers in all AON bands, except in the AON band between 7 - 8 years where it is almost simillar.\n",
    "- Total outgoing MOU avg. for Aug(_8) cease to increace, infact it shows a significant decline compared to Jul(_7).\n",
    "- Total outgoing MOU avg. for Sep(_9) is the lowest of all 4 months.\n",
    "- The Avg. outgoing usage reduces drastically for customers in the AON band between 7 - 8  years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-KkCPRew1ee"
   },
   "source": [
    "###### Incoming/Outgoing MOU VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ad9tzMNw1ee",
    "outputId": "162f265b-b42c-416e-9da9-bd4f1732c167"
   },
   "outputs": [],
   "source": [
    "ic_col = ['total_ic_mou_6','total_ic_mou_7','total_ic_mou_8']\n",
    "og_col = ['total_og_mou_6','total_og_mou_7','total_og_mou_8']\n",
    "plot_byChurnMou(ic_col,'Incoming')\n",
    "plot_byChurnMou(og_col,'Outgoing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YpPIQCYHw1eg"
   },
   "source": [
    "It can be observed,\n",
    "- Churners Avg. Incoming/Outgoing MOU's **drops drastically after the 2nd month,Jul.**\n",
    "- While the non-churners Avg. MOU's remains consistant and stable with each month.\n",
    "- Therefore, users MOU is a key feature to predict churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7mNl0Wnw1eg"
   },
   "source": [
    "Let's also see this trend in terms of actual numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zg_UGyCiw1eg",
    "outputId": "0be18e15-603e-4944-afb9-eb28e150360f"
   },
   "outputs": [],
   "source": [
    "# Avg.Incoming MOU per month churn vs Non-Churn\n",
    "hv_users.groupby(['churn'])['total_ic_mou_6','total_ic_mou_7','total_ic_mou_8'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTFhYfhvw1ek",
    "outputId": "f120f999-777f-4d25-dc08-d43db3b12abc"
   },
   "outputs": [],
   "source": [
    "# Avg. Outgoing MOU per month churn vs Non-Churn\n",
    "hv_users.groupby(['churn'])['total_og_mou_6','total_og_mou_7','total_og_mou_8'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMET-OJ3w1el"
   },
   "source": [
    "**Create new feature:** og_to_ic_mou_6, og_to_ic_mou_7, og_to_ic_mou_8\n",
    "These features will hold the **ratio** (=total_og_mou_* / total_ic_mou_*) for each month. These features will combine both incoming and outgoing informations and should be a **better predictor of churn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mohKvwpw1em"
   },
   "outputs": [],
   "source": [
    "#Creating new feature: og_to_ic_mou_6, og_to_ic_mou_7, og_to_ic_mou_8\n",
    "# adding 1 to denominator to avoid dividing by 0 and getting nan values.\n",
    "for i in range(6,9):\n",
    "    hv_users['og_to_ic_mou_'+str(i)] = (hv_users['total_og_mou_'+str(i)])/(hv_users['total_ic_mou_'+str(i)]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUBGgIHGw1en",
    "outputId": "883997f0-f8b5-493b-c995-0147153a458c"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'og_to_ic_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eubdG6kPw1eq"
   },
   "source": [
    "- Outgoing to incoming mou remains drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HXUxnd3w1er"
   },
   "source": [
    "**Create new feature:** loc_og_to_ic_mou_6, loc_og_to_ic_mou_7, loc_og_to_ic_mou_8\n",
    "These features will hold the **ratio** (=loc_og_mou_* / loc_ic_mou_*) for each month. These features will combine the local calls, both incoming and outgoing informations and should be a **better predictor of churn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1U3e9bkHw1es"
   },
   "outputs": [],
   "source": [
    "#Create new feature: loc_og_to_ic_mou_6, loc_og_to_ic_mou_7, loc_og_to_ic_mou_8\n",
    "# adding 1 to denominator to avoid dividing by 0 and getting nan values.\n",
    "for i in range(6,9):\n",
    "    hv_users['loc_og_to_ic_mou_'+str(i)] = (hv_users['loc_og_mou_'+str(i)])/(hv_users['loc_ic_mou_'+str(i)]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6cv9ZB8w1ev",
    "outputId": "671f1e6d-075f-49b9-ae6a-b5c76aa8abfe"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'loc_og_to_ic_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqAf55Avw1ey"
   },
   "source": [
    "It can be observed that,\n",
    "- The local outgoing to incoming call mou ratio is genrally low for churners right from the begining of the good phase.\n",
    "- local mou pattern for the non-churners remains almost constant through out the 3 months.\n",
    "- The churners genrally show a low loc mou ratio but it drops dramatically after the 2nd month.\n",
    "- This might suggest that people who are not making/reciving much local calls during their tenure are more likely to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kMvYzHlvw1ez"
   },
   "source": [
    "###### Total data volume VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISBgmK4Ew1e0",
    "outputId": "91cad954-f998-4094-e3c3-07163a731147"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'vol_data_mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-VlRoFYw1e2"
   },
   "source": [
    "- The volume of data mb used drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_w1XwBjw1e4"
   },
   "source": [
    "###### Total monthly rech VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kA7BHg4pw1e4",
    "outputId": "bf6d565c-4316-429b-aa8f-f43c17573d75"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'total_month_rech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MNVEbzYw1e7"
   },
   "source": [
    "- total monthly rech amount also drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhGGc61cw1e7"
   },
   "source": [
    "###### max_rech_amt VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uvx_xVncw1e7",
    "outputId": "35a244f4-72eb-41b8-e48e-d85ca352c1d6"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'max_rech_amt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qr8ZKwCdw1e9"
   },
   "source": [
    "- maximum recharge amount also drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxxptRORw1e9"
   },
   "source": [
    "###### arpu VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3P2OhmWSw1e9",
    "outputId": "f4fed0f6-1249-4391-8789-296b542d7422"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'arpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CC2oHkGuw1e_"
   },
   "source": [
    "- Average revenue per user,arpu also drops significantly for churners from month Jul(6) to Aug(7).\n",
    "- While it remains almost consistent for the non-churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYESr0Aiw1e_"
   },
   "source": [
    "**Create new feature:** Total_loc_mou_6, Total_loc_mou_7, Total_loc_mou_8<br>\n",
    "These features will hold the **Total MOU** (=loc_og_mou+loc_ic_mou) for each month.<br>\n",
    "Using this we will find if the loc MOU (both incoming and outgoing) drops or increaces as the months goes by.<br>\n",
    "This informations should be a **better predictor of churn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5OHv6J8Kw1e_"
   },
   "outputs": [],
   "source": [
    "#Create new feature: Total_loc_mou_6,Total_loc_mou_7,lTotal_loc_mou_8\n",
    "for i in range(6,9):\n",
    "    hv_users['Total_loc_mou_'+str(i)] = (hv_users['loc_og_mou_'+str(i)])+(hv_users['loc_ic_mou_'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EXeBuA-w1fA",
    "outputId": "833f782f-7c77-430a-a2c7-a87a54597c89"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'Total_loc_mou_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71GBXam5w1fC"
   },
   "source": [
    "It can be observed that,\n",
    "- The Total local call mou is genrally low for churners right from the begining of the good phase.\n",
    "- local mou pattern for the non-churners remains almost constant through out the 3 months.\n",
    "- The churners genrally show a low total loc mou but it drops dramatically after the 2nd month.\n",
    "- This might suggest that people who are not making/reciving much local calls during their tenure are more likely to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3323CYvCw1fC"
   },
   "source": [
    "**Create new feature:** Total_roam_mou_6,Total_roam_mou_7,Total_roam_mou_8<br>\n",
    "These features will hold the **Total roaming MOU** (=roam_ic_mou+roam_og_mou) for each month.<br>\n",
    "Using this we will find if the roam MOU (both incoming and outgoing) drops or increaces as the months goes by.<br>\n",
    "This informations should be a **better predictor of churn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rz2Tf5bVw1fC"
   },
   "outputs": [],
   "source": [
    "#Create new feature: Total_roam_mou_6,Total_roam_mou_7,Total_roam_mou_8\n",
    "for i in range(6,9):\n",
    "    hv_users['Total_roam_mou_'+str(i)] = (hv_users['roam_ic_mou_'+str(i)])+(hv_users['roam_og_mou_'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1OXqg8LHw1fE",
    "outputId": "52f4d169-17c5-444b-b0fc-58a7a8dd4087"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'Total_roam_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNc3fdPAw1fF"
   },
   "source": [
    "It can be observed that,\n",
    "- Surprisingly, the roaming usage of churners is way higher than those of non-churners across all months\n",
    "- People who are making/reciving more roaming calls during their tenure are more likely to churn.\n",
    "- This might suggest that the operators roaming tariffs are higher than what are offered by its competitor, thus forming one of the reasons of churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wch0B-XNw1fG"
   },
   "source": [
    "###### last_day_rch_amt VS Churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fB7WAP5xw1fG",
    "outputId": "6d6134da-cba4-426d-850e-662ef0fc9cc4"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'last_day_rch_amt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a400Ib-fw1fH"
   },
   "source": [
    "- The avg. last recharge amount for churners is less than half the amount of that of the non-churners.\n",
    "- Suggesting, as the recharge amount reduces for a customer its chances to churn increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yenNQmIHw1fI"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1hakLJ3Tw1fJ"
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3TbLJ8tw1fK"
   },
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DSqyqoQw1fM"
   },
   "outputs": [],
   "source": [
    "def getModelMetrics(actual_churn=False,pred_churn=False):\n",
    "\n",
    "    confusion = metrics.confusion_matrix(actual_churn, pred_churn)\n",
    "\n",
    "    TP = confusion[1,1] # true positive \n",
    "    TN = confusion[0,0] # true negatives\n",
    "    FP = confusion[0,1] # false positives\n",
    "    FN = confusion[1,0] # false negatives\n",
    "\n",
    "    print(\"Roc_auc_score : {}\".format(metrics.roc_auc_score(actual_churn,pred_churn)))\n",
    "    # Let's see the sensitivity of our logistic regression model\n",
    "    print('Sensitivity/Recall : {}'.format(TP / float(TP+FN)))\n",
    "    # Let us calculate specificity\n",
    "    print('Specificity: {}'.format(TN / float(TN+FP)))\n",
    "    # Calculate false postive rate - predicting churn when customer does not have churned\n",
    "    print('False Positive Rate: {}'.format(FP/ float(TN+FP)))\n",
    "    # positive predictive value \n",
    "    print('Positive predictive value: {}'.format(TP / float(TP+FP)))\n",
    "    # Negative predictive value\n",
    "    print('Negative Predictive value: {}'.format(TN / float(TN+ FN)))\n",
    "    # sklearn precision score value \n",
    "    print('sklearn precision score value: {}'.format(metrics.precision_score(actual_churn, pred_churn )))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6BgW8zhw1fN"
   },
   "outputs": [],
   "source": [
    "def predictChurnWithProb(model,X,y,prob):\n",
    "    # Funtion to predict the churn using the input probability cut-off\n",
    "    # Input arguments: model instance, x and y to predict using model and cut-off probability\n",
    "    \n",
    "    # predict\n",
    "    pred_probs = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    y_df= pd.DataFrame({'churn':y, 'churn_Prob':pred_probs})\n",
    "    # Creating new column 'predicted' with 1 if Churn_Prob>0.5 else 0\n",
    "    y_df['final_predicted'] = y_df.churn_Prob.map( lambda x: 1 if x > prob else 0)\n",
    "    # Let's see the head\n",
    "    getModelMetrics(y_df.churn,y_df.final_predicted)\n",
    "    return y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fE8Fneyow1fO"
   },
   "outputs": [],
   "source": [
    "def findOptimalCutoff(df):\n",
    "    #Function to find the optimal cutoff for classifing as churn/non-churn\n",
    "    # Let's create columns with different probability cutoffs \n",
    "    numbers = [float(x)/10 for x in range(10)]\n",
    "    for i in numbers:\n",
    "        df[i] = df.churn_Prob.map( lambda x: 1 if x > i else 0)\n",
    "    #print(df.head())\n",
    "    \n",
    "    # Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "    cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    # TP = confusion[1,1] # true positive \n",
    "    # TN = confusion[0,0] # true negatives\n",
    "    # FP = confusion[0,1] # false positives\n",
    "    # FN = confusion[1,0] # false negatives\n",
    "    \n",
    "    num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "    for i in num:\n",
    "        cm1 = metrics.confusion_matrix(df.churn, df[i] )\n",
    "        total1=sum(sum(cm1))\n",
    "        accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "        \n",
    "        speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "        sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "        cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "    print(cutoff_df)\n",
    "    # Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "    cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEgMZIkQw1fP"
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train, y_train, performCV=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, X_train, y_train, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.roc_auc_score(y_train, dtrain_predictions))\n",
    "    print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_train, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXvYnp8uw1fQ"
   },
   "outputs": [],
   "source": [
    "# creating copy of the final hv_user dataframe\n",
    "hv_users_PCA = hv_users.copy()\n",
    "# removing the columns not required for modeling\n",
    "hv_users_PCA.drop(['mobile_number', 'aon_bin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW9k6Csqw1fR",
    "outputId": "b96227de-f63c-4526-e752-44024f974ce0"
   },
   "outputs": [],
   "source": [
    "# removing the datatime columns before PCA\n",
    "dateTimeCols = list(hv_users_PCA.select_dtypes(include=['datetime64']).columns)\n",
    "print(dateTimeCols)\n",
    "hv_users_PCA.drop(dateTimeCols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAPhWaMSw1fS"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#putting features variables in X\n",
    "X = hv_users_PCA.drop(['churn'], axis=1)\n",
    "\n",
    "#putting response variables in Y\n",
    "y = hv_users_PCA['churn']    \n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z--kUh-iw1fT"
   },
   "outputs": [],
   "source": [
    "#Rescaling the features before PCA as it is sensitive to the scales of the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2f_rpgxBw1fV"
   },
   "outputs": [],
   "source": [
    "# fitting and transforming the scaler on train\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# transforming the train using the already fit scaler\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkIe1eD0w1fW"
   },
   "source": [
    "### Handling class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4uGI0Huw1fW"
   },
   "source": [
    "Standard classifier algorithms like Decision Tree and Logistic Regression have a bias towards classes which have number of instances. They tend to only predict the majority class data. The features of the minority class are treated as noise and are often ignored. Thus, there is a high probability of misclassification of the minority class as compared to the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgs0KgEow1fX"
   },
   "source": [
    "**Informed Over Sampling: Synthetic Minority Over-sampling Technique**\n",
    "\n",
    "This technique is followed to avoid overfitting which occurs when exact replicas of minority instances are added to the main dataset. A subset of data is taken from the minority class as an example and then new synthetic similar instances are created. These synthetic instances are then added to the original dataset. The new dataset is used as a sample to train the classification models.\n",
    "\n",
    "**Advantages**\n",
    "- Mitigates the problem of overfitting caused by random oversampling as synthetic examples are generated rather than replication of instances\n",
    "- No loss of useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBksqpD9w1fY",
    "outputId": "be2eb3e5-8361-4d03-fc9b-bc279346b9da"
   },
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "print(\"Before OverSampling, churn event rate : {}% \\n\".format(round(sum(y_train==1)/len(y_train)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UV-UfJeXw1fa"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=12, sampling_strategy = 1)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9M3hofiw1fb",
    "outputId": "fedbc2e6-0954-44e4-e1d9-8abe0ea110a6"
   },
   "outputs": [],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "print(\"After OverSampling, churn event rate : {}% \\n\".format(round(sum(y_train_res==1)/len(y_train_res)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b__lZfLhw1fd"
   },
   "outputs": [],
   "source": [
    "#Improting the PCA module\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='randomized', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQ1FFsOhw1fe",
    "outputId": "79bc92dc-31fb-4795-c878-693bcf72c21f"
   },
   "outputs": [],
   "source": [
    "#Doing the PCA on the train data\n",
    "pca.fit(X_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STcH9AhQw1fh"
   },
   "source": [
    "we'll let PCA select the number of components basen on a variance cutoff we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnSzruK5w1fh"
   },
   "outputs": [],
   "source": [
    "# let PCA select the number of components basen on a variance cutoff \n",
    "#pca_again = PCA(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMdSv6IHw1fk"
   },
   "outputs": [],
   "source": [
    "#df_train_pca2 = pca_again.fit_transform(X_train_res)\n",
    "#df_train_pca2.shape\n",
    "# we see that PCA selected 12 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCczzZebw1fl"
   },
   "outputs": [],
   "source": [
    "#X_train_pca = pca_again.fit_transform(X_train_res)\n",
    "#X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNrvMvRWw1fm"
   },
   "outputs": [],
   "source": [
    "#Applying selected components to the test data - 50 components\n",
    "#X_test_pca = pca_again.transform(X_test)\n",
    "#X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KZkNluIw1fn"
   },
   "source": [
    " **Looking at the screeplot to assess the number of needed principal components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KhM_cr5hw1fn",
    "outputId": "bd7368f1-7df8-4142-b542-cb292359ab91",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2OwZ4EFw1fo",
    "outputId": "574e10dd-1b81-4cf4-b431-3a54c0eeffc0"
   },
   "outputs": [],
   "source": [
    "#Making the screeplot - plotting the cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udrcPf5Iw1fq"
   },
   "source": [
    "##### **Looks like 50 components are enough to describe 95% of the variance in the dataset**\n",
    "- We'll choose 50 components for our modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHZTR_stw1fr"
   },
   "outputs": [],
   "source": [
    "#Using incremental PCA for efficiency - saves a lot of time on larger datasets\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca_final = IncrementalPCA(n_components=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2yX4W7Ow1fs",
    "outputId": "bbcc3541-5a9d-4166-ac9b-6ef4617f7132"
   },
   "outputs": [],
   "source": [
    "X_train_pca = pca_final.fit_transform(X_train_res)\n",
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpTK1PQgw1ft",
    "outputId": "f89e0c4e-3c48-4998-c956-71a9425940f8"
   },
   "outputs": [],
   "source": [
    "#creating correlation matrix for the principal components\n",
    "corrmat = np.corrcoef(X_train_pca.transpose())\n",
    "# 1s -> 0s in diagonals\n",
    "corrmat_nodiag = corrmat - np.diagflat(corrmat.diagonal())\n",
    "print(\"max corr:\",corrmat_nodiag.max(), \", min corr: \", corrmat_nodiag.min(),)\n",
    "# we see that correlations are indeed very close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19FTPt1zw1fu"
   },
   "source": [
    "Indeed - there is no correlation between any two components! We effectively have removed multicollinearity from our situation, and our models will be much more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Nunv3tRw1fu",
    "outputId": "78522773-89de-4a36-cbb1-0588ac55b635"
   },
   "outputs": [],
   "source": [
    "#Applying selected components to the test data - 50 components\n",
    "X_test_pca = pca_final.transform(X_test)\n",
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmCzPcnsxHDw"
   },
   "source": [
    "For the prediction of churn customers we will be fitting variety of models and select one which is the best predictor of churn. Models trained are,\n",
    "    1. Logistic Regression\n",
    "    2. Decision Tree\n",
    "    3. Random Forest\n",
    "    4. Boosting models - Gradient Boosting Classifier and XGBoost Classifier\n",
    "    5. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddW2stNaw1fy"
   },
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYSQFnDNw1fy"
   },
   "source": [
    "##### Applying Logistic Regression on our principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74Z1Hy6lw1f2"
   },
   "outputs": [],
   "source": [
    "#Training the model on the train data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lr0 = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShmQYRQHw1f3",
    "outputId": "183b3d74-a4c9-4633-e056-de85aeb26f4a"
   },
   "outputs": [],
   "source": [
    "modelfit(lr0, X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BIHEyLTw1f4",
    "outputId": "deb2896c-9c5e-4a6e-a4ec-9c2b69885c5e"
   },
   "outputs": [],
   "source": [
    "# predictions on Test data\n",
    "pred_probs_test = lr0.predict(X_test_pca)\n",
    "getModelMetrics(y_test,pred_probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZE9bMymJw1f5",
    "outputId": "6e0b2a95-ff17-450a-c296-ce802ab615ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(y_test,pred_probs_test)))\n",
    "print(\"Recall : {}\".format(metrics.recall_score(y_test,pred_probs_test)))\n",
    "print(\"Precision : {}\".format(metrics.precision_score(y_test,pred_probs_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTSmumobw1f8",
    "outputId": "0b106229-6acd-4b18-f256-531d7d7a1cda"
   },
   "outputs": [],
   "source": [
    "#Making prediction on the test data\n",
    "pred_probs_train = lr0.predict_proba(X_train_pca)[:,1]\n",
    "print(\"roc_auc_score(Train) {:2.2}\".format(metrics.roc_auc_score(y_train_res, pred_probs_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Two0-tttw1gE",
    "outputId": "da74791b-06c9-4c89-c17c-9dd3d96b43f1"
   },
   "outputs": [],
   "source": [
    "cut_off_prob=0.5\n",
    "y_train_df = predictChurnWithProb(lr0,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdBWN_GKw1gG"
   },
   "source": [
    "**Plotting the ROC Curve :**\n",
    "An ROC curve demonstrates several things:\n",
    "\n",
    "- It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n",
    "- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n",
    "- The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KM_E4-ffw1gG",
    "outputId": "f0fc2c14-3980-4f31-e901-b91ad0efb40d"
   },
   "outputs": [],
   "source": [
    "draw_roc(y_train_df.churn, y_train_df.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaExGch_w1gI"
   },
   "source": [
    "The roc curve is lying in the top left corner which is a sign of a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MmIrkX9w1gJ",
    "outputId": "fce7e14b-6611-434e-8863-7dd60ffe988f"
   },
   "outputs": [],
   "source": [
    "#draw_roc(y_pred_final.Churn, y_pred_final.predicted)\n",
    "print(\"roc_auc_score : {:2.2f}\".format(metrics.roc_auc_score(y_train_df.churn, y_train_df.final_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8O9FgFaw1gL"
   },
   "source": [
    "**Finding Optimal Cutoff Point**<br>\n",
    "Since recall or sensitivity is a much more important metrics for churn prediction. A trade off between sensitivity(or recall) and specificity is to be considered in doing so. We will try adjusting the probability threshold which shall lead to higher sensitivity or recall rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kf3tderOw1gL",
    "outputId": "f91ef123-1b47-4a35-98d3-f978bd087bc8"
   },
   "outputs": [],
   "source": [
    "# finding cut-off with the right balance of the metrices\n",
    "# sensitivity vs specificity trade-off\n",
    "findOptimalCutoff(y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o7WGRV_Hw1gN"
   },
   "source": [
    "#### **From the curve above, 0.45 is the optimum point .**\n",
    "Although, other cutoff between 0.4 and 0.6 can also be taken but to keep the test sensitivity/recall significant we choose 0.45. At this point there is a balance of sensitivity, specificity and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRv0BqTVw1gN",
    "outputId": "3d3fcb39-cc39-46c8-dd8b-959ba24096ec"
   },
   "outputs": [],
   "source": [
    "# predicting with the choosen cut-off on train\n",
    "cut_off_prob = 0.45\n",
    "predictChurnWithProb(lr0,X_train_pca,y_train_res,cut_off_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Go7Fnixw1gO"
   },
   "source": [
    "**Making prediction on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKY1YYVow1gP",
    "outputId": "4a4cccd7-3dd5-4999-e99e-74ae98b20837"
   },
   "outputs": [],
   "source": [
    "# predicting with the choosen cut-off on test\n",
    "predictChurnWithProb(lr0,X_test_pca,y_test,cut_off_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQiUjiQcw1gQ"
   },
   "source": [
    "The resulting model, after PCA and logistic regression (with optimal cutoff setting) has a right balance of different metrics score for sensitivity, specificity and Roc Accuracy on the train and test set.\n",
    "- **train sensitivity  :** 86.47%, **train roc auc score  :** 82.1%\n",
    "- **test sensitivity   :** 84.40%, **test roc auc score  :** 81.21%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUZpKshPw1gQ"
   },
   "source": [
    "### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFFPJTG4w1gQ"
   },
   "source": [
    "##### Applying Decision Tree Classifier on our principal components with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1-91gmhw1gQ",
    "outputId": "21c074ac-4a82-495a-8197-9c656f2fdb46"
   },
   "outputs": [],
   "source": [
    "dt0 = DecisionTreeClassifier(class_weight='balanced',\n",
    "                             max_features='auto',\n",
    "                             min_samples_split=100,\n",
    "                             min_samples_leaf=100,\n",
    "                             max_depth=6,\n",
    "                             random_state=10)\n",
    "modelfit(dt0, X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DMvsTkDMw1gT",
    "outputId": "6e435fdc-0611-4c01-87b6-3ee28085d116"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred_probs_test = dt0.predict(X_test_pca)\n",
    "#Let's check the model metrices.\n",
    "getModelMetrics(actual_churn=y_test,pred_churn=pred_probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pj9OcaFew1gU"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': range(5,15,3),\n",
    "    'min_samples_leaf': range(100, 400, 50),\n",
    "    'min_samples_split': range(100, 400, 100),\n",
    "    'max_features': [8,10,15]\n",
    "}\n",
    "# Create a based model\n",
    "dt = DecisionTreeClassifier(class_weight='balanced',random_state=10)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = dt, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 4,verbose = 1,scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy13PLucw1gV",
    "outputId": "1f0378de-25be-42e3-f2af-a2190c3ecc7c"
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UX48ntdqw1gW",
    "outputId": "0d97e677-7869-45b3-e44a-5dd79f5faf82"
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get recall of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byVSAxvww1gZ"
   },
   "outputs": [],
   "source": [
    "# model with the best hyperparameters\n",
    "dt_final = DecisionTreeClassifier(class_weight='balanced',\n",
    "                             max_depth=14,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=100,\n",
    "                             max_features=15,\n",
    "                             random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3APjfT9w1ga",
    "outputId": "d9f12dac-a2b1-4f62-b2ba-98d88287691d"
   },
   "outputs": [],
   "source": [
    "modelfit(dt_final,X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6aY4FBcw1gb",
    "outputId": "c74cb7d6-1dd5-4c6f-f503-a7d3d5272a84"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred_probs_test = dt_final.predict(X_test_pca)\n",
    "#Let's check the model metrices.\n",
    "getModelMetrics(actual_churn=y_test,pred_churn=pred_probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBXXQxNpw1gc",
    "outputId": "ee5f5e32-073d-4f7c-ee21-c1c2882599ef"
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test,pred_probs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RtiGCfKw1gd"
   },
   "source": [
    "Even after hyperparameter tuning for the Decision Tree. The recall rate is 67.54% which is not very significant to predict the churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kYp9A-qw1ge"
   },
   "source": [
    "Let's see if we can achive a better Recall rate by deciding an optimal cut-off for the model to predict churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvdGqTxaw1gf",
    "outputId": "76e54361-7816-44ae-ba50-b506bdbfbe5d"
   },
   "outputs": [],
   "source": [
    "# predicting churn with default cut-off 0.5\n",
    "cut_off_prob = 0.5\n",
    "y_train_df = predictChurnWithProb(dt_final,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i38pLQJOw1gj",
    "outputId": "1a2eec91-0040-4ae5-e45b-10cde227adb5"
   },
   "outputs": [],
   "source": [
    "# finding cut-off with the right balance of the metrices\n",
    "findOptimalCutoff(y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztxqIP5Yw1gl"
   },
   "source": [
    "**From the curve above, let'choose 0.4 as the optimum point to make a high enough sensitivity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nr_3qhjrw1gm",
    "outputId": "ba3fc6df-7e7c-424b-c79b-2137e836764f"
   },
   "outputs": [],
   "source": [
    "# predicting churn with cut-off 0.4\n",
    "cut_off_prob=0.4\n",
    "y_train_df = predictChurnWithProb(dt_final,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GvmbpdC9w1gp"
   },
   "source": [
    "- At 0.58 cut-off prob. there is a balance of sensitivity , specificity and accuracy.\n",
    "<br>Lets see how it performs on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XF5NfQfUw1gp",
    "outputId": "5d0231fa-3456-4381-9ad4-c2de619f04c4"
   },
   "outputs": [],
   "source": [
    "#Lets see how it performs on test data.\n",
    "y_test_df= predictChurnWithProb(dt_final,X_test_pca,y_test,cut_off_prob)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2d4DEJBcw1gr"
   },
   "source": [
    "- Decision tree after selecting optimal cut-off also is resulting in a model with\n",
    "<br>**Train Recall : 89.78%**  and  **Train Roc_auc_score : 82.40**\n",
    "<br>**Test Recall : 78.13%**  and  **Test Roc_auc_score : 76.56**\n",
    "\n",
    "Random Forest still seems overfitted to the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibcAPYP7w1gr"
   },
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9x27df2Dw1gs"
   },
   "source": [
    "##### Applying Random Forest Classifier on our principal components with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nq4aUbCw1gs"
   },
   "outputs": [],
   "source": [
    "def plot_traintestAcc(score,param):\n",
    "    scores = score\n",
    "    # plotting accuracies with max_depth\n",
    "    plt.figure()\n",
    "    plt.plot(scores[\"param_\"+param], \n",
    "    scores[\"mean_train_score\"], \n",
    "    label=\"training accuracy\")\n",
    "    plt.plot(scores[\"param_\"+param], \n",
    "    scores[\"mean_test_score\"], \n",
    "    label=\"test accuracy\")\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"f1\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3Aa5rJsw1gt"
   },
   "source": [
    "#### Tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcLFOjAWw1gt",
    "outputId": "3815d224-de79-493e-e128-50cff47277fb"
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(10, 30, 5)}\n",
    "rf0 = RandomForestClassifier()\n",
    "rfgs = GridSearchCV(rf0, parameters, \n",
    "                    cv=5, \n",
    "                   scoring=\"f1\",return_train_score=True)\n",
    "rfgs.fit(X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39xJv9jyw1gx",
    "outputId": "86e33e18-3f31-4d67-984f-d542117ac282"
   },
   "outputs": [],
   "source": [
    "scores = rfgs.cv_results_\n",
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hTULp06w1gy"
   },
   "source": [
    "Test f1-score almost becomes constant after max_depth=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9WuZSfww1g2"
   },
   "source": [
    "#### Tuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWiqB9X-w1g2"
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': range(50, 150, 25)}\n",
    "rf1 = RandomForestClassifier(max_depth=20,random_state=10)\n",
    "rfgs = GridSearchCV(rf1, parameters, \n",
    "                    cv=3, \n",
    "                   scoring=\"recall\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIHOqq0Cw1g3",
    "outputId": "bc6d9a0a-3e02-4c7b-8082-050525c47e2d"
   },
   "outputs": [],
   "source": [
    "rfgs.fit(X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SX9-R5juw1g4",
    "outputId": "c6034ff0-016c-4215-aa5a-ddd4c3923a91"
   },
   "outputs": [],
   "source": [
    "plot_traintestAcc(rfgs.cv_results_,'n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhrCDKqyw1g5"
   },
   "source": [
    "Selecting n_estimators = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7YVGrqKw1g5"
   },
   "source": [
    "#### Tuning max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2BzJ6kAw1g5"
   },
   "outputs": [],
   "source": [
    "parameters = {'max_features': [4, 8, 14, 20, 24]}\n",
    "rf3 = RandomForestClassifier(max_depth=20,n_estimators=80,random_state=10)\n",
    "rfgs = GridSearchCV(rf3, parameters, \n",
    "                    cv=5, \n",
    "                   scoring=\"f1\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVC2mt3cw1g6",
    "outputId": "617905d2-227c-428d-daf8-fceaefa833d6"
   },
   "outputs": [],
   "source": [
    "rfgs.fit(X_train_pca,y_train_res)\n",
    "plot_traintestAcc(rfgs.cv_results_,'max_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oJ9rk-aw1g8"
   },
   "source": [
    "Selecting max_features = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ak4zK8ORw1g8"
   },
   "source": [
    "#### Tuning min_sample_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61tYYGDXw1g8"
   },
   "outputs": [],
   "source": [
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "rf4 = RandomForestClassifier(max_depth=20,n_estimators=80,max_features=5,random_state=10)\n",
    "rfgs = GridSearchCV(rf4, parameters, \n",
    "                    cv=3, \n",
    "                   scoring=\"f1\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3j8-O39w1g9",
    "outputId": "efbf4fec-fa01-41a7-beb6-de8311afa194"
   },
   "outputs": [],
   "source": [
    "rfgs.fit(X_train_pca,y_train_res)\n",
    "plot_traintestAcc(rfgs.cv_results_,'min_samples_leaf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "708QXSomw1hB"
   },
   "source": [
    "Selecting min_sample_leaf = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCPOdDG7w1hC"
   },
   "source": [
    "#### Tuning min_sample_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmfgz2iqw1hC"
   },
   "outputs": [],
   "source": [
    "parameters = {'min_samples_split': range(50, 300, 50)}\n",
    "rf5 = RandomForestClassifier(max_depth=20,n_estimators=80,max_features=5,min_samples_leaf=100,random_state=10)\n",
    "rfgs = GridSearchCV(rf5, parameters, \n",
    "                    cv=3, \n",
    "                   scoring=\"f1\",return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pg1NOHK3w1hD",
    "outputId": "c748437b-cc8c-4f5f-f938-f622eaffad99"
   },
   "outputs": [],
   "source": [
    "rfgs.fit(X_train_pca,y_train_res)\n",
    "plot_traintestAcc(rfgs.cv_results_,'min_samples_split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfaaGBWpw1hD"
   },
   "source": [
    "Selecting min_sample_split = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yc7S_S7-w1hE"
   },
   "source": [
    "#### Tunned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGnem99_w1hE"
   },
   "outputs": [],
   "source": [
    "rf_final = RandomForestClassifier(max_depth=20,\n",
    "                                  n_estimators=80,\n",
    "                                  max_features=5,\n",
    "                                  min_samples_leaf=100,\n",
    "                                  min_samples_split=50,\n",
    "                                  random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eoZud2cw1hF",
    "outputId": "310623e7-866b-4035-a282-22435089e30e"
   },
   "outputs": [],
   "source": [
    "print(\"Model performance on Train data:\")\n",
    "modelfit(rf_final,X_train_pca,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDqvkeGtw1hG"
   },
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "predictions = rf_final.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6Q0_FlFw1hH",
    "outputId": "0b34f150-7bb2-4fdd-92fe-4792b8e89054"
   },
   "outputs": [],
   "source": [
    "print(\"Model performance on Test data:\")\n",
    "getModelMetrics(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ps5j9Bhfw1hK"
   },
   "source": [
    "After hyperparameter tuning for the random forest. The Recall rate(Test) is 73.39%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXoHArQqw1hK"
   },
   "source": [
    "Let's see if we can achive a better Recall rate by deciding an optimal cut-off for the model to predict churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_73q_ORw1hK",
    "outputId": "b21030af-ce86-4b52-8daf-1a462a914e51"
   },
   "outputs": [],
   "source": [
    "# predicting churn with default cut-off 0.5\n",
    "cut_off_prob=0.5\n",
    "y_train_df = predictChurnWithProb(rf_final,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iuevuj3fw1hL",
    "outputId": "1acc35c9-4d2f-478b-b17b-163bc3892079"
   },
   "outputs": [],
   "source": [
    "# finding cut-off with the right balance of the metrices\n",
    "findOptimalCutoff(y_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7x1c1sQ0w1hM"
   },
   "source": [
    "**From the curve above, 0.45 is the optimal point with high enough sensitivity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chBp01Zjw1hM",
    "outputId": "68431683-fb0e-4669-ffcb-d79d21a46ab3"
   },
   "outputs": [],
   "source": [
    "cut_off_prob=0.45\n",
    "predictChurnWithProb(rf_final,X_train_pca,y_train_res,cut_off_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECt8XBALw1hN"
   },
   "source": [
    "**Making prediction on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mJb2m5-w1hO",
    "outputId": "82cf8e43-8138-4f73-acf5-459ec5bd1dc9"
   },
   "outputs": [],
   "source": [
    "y_test_df= predictChurnWithProb(rf_final,X_test_pca,y_test,cut_off_prob)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5vBEjRXw1hO"
   },
   "source": [
    "- Random Forest after selecting optimal cut-off also is resulting in a model with\n",
    "<br>**Train Recall : 88.70%**  and  **Train Roc_auc_score : 85.60**\n",
    "<br>**Test Recall : 77.57%**  and  **Test Roc_auc_score : 79.65**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n40kKPV5w1hP"
   },
   "source": [
    "### 4. Boosting models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBeP8_Izw1hP"
   },
   "source": [
    "###### 4.1 Gradiant boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVpngZAiw1hP"
   },
   "source": [
    "###### Applying Gradiant boosting Classifier on our principal components with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juWuBs6Rw1hP",
    "outputId": "973384d7-2592-4663-b41d-dc30430681f2"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "# Fitting the default GradientBoostingClassifier\n",
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "modelfit(gbm0, X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o1n9Mbtaw1hR",
    "outputId": "02a78129-b55a-414e-cb4f-86ea14552687"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for n_estimators\n",
    "param_test1 = {'n_estimators':range(20,150,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='f1',n_jobs=4,iid=False, cv=3,return_train_score=True)\n",
    "gsearch1.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awIpQ3J3w1hS",
    "outputId": "72a6c3cb-df55-49f2-9b12-5f30fdad4a82"
   },
   "outputs": [],
   "source": [
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4In1axiw1hT",
    "outputId": "043a734d-299a-4576-c86f-3183e8d39151"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for max_depth and min_sample_split\n",
    "param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=140, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test2, scoring='f1',n_jobs=4,iid=False, cv=3)\n",
    "gsearch2.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuPAa3L-w1hU",
    "outputId": "d796bc0b-583b-4edc-cdf3-ad5f24e63176"
   },
   "outputs": [],
   "source": [
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aM4EZQUGw1hU",
    "outputId": "5df35d78-ee1e-4277-8846-b8e33b6f1323"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for min_sample_leaf\n",
    "param_test3 = {'min_samples_leaf':range(30,71,10)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=140,max_depth=15,min_samples_split=200, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test3, scoring='f1',n_jobs=4,iid=False, cv=3,return_train_score=True)\n",
    "gsearch3.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UTMMU4Ew1hV",
    "outputId": "3f261fe4-18d0-4c2b-cc3c-6fdfc711bbc0"
   },
   "outputs": [],
   "source": [
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mtTH-gOrw1hW",
    "outputId": "6e9a765c-2df9-4070-fb64-840176da49ad"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for max_features\n",
    "param_test4 = {'max_features':range(7,20,2)}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=140,max_depth=15, min_samples_split=200, min_samples_leaf=30, subsample=0.8, random_state=10),\n",
    "param_grid = param_test4, scoring='f1',n_jobs=4,iid=False, cv=3,return_train_score=True)\n",
    "gsearch4.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZlVI975w1hY",
    "outputId": "4b11331c-84f0-473a-d1c6-302722855310"
   },
   "outputs": [],
   "source": [
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LVhiJZdw1hZ"
   },
   "source": [
    "Tunned GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PEkNKOWw1hZ",
    "outputId": "35975d69-2937-482b-81fb-0ca5b696ba05"
   },
   "outputs": [],
   "source": [
    "# Tunned GradientBoostingClassifier\n",
    "gbm_final = GradientBoostingClassifier(learning_rate=0.1, n_estimators=140,max_features=15,max_depth=15, min_samples_split=200, min_samples_leaf=40, subsample=0.8, random_state=10)\n",
    "modelfit(gbm_final, X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZHsz-eDw1ha"
   },
   "outputs": [],
   "source": [
    "# predictions on Test data\n",
    "dtest_predictions = gbm_final.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U57mOa8Vw1hb",
    "outputId": "7a1ba351-84df-4f38-cf99-87d0b2f3c8d1"
   },
   "outputs": [],
   "source": [
    "# model Performance on test data\n",
    "getModelMetrics(y_test,dtest_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9USh56lw1hc"
   },
   "source": [
    "Let's see if we can achive a better Recall rate by deciding an optimal cut-off for the model to predict churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnXt8yEJw1hc",
    "outputId": "943b508b-4ccc-437e-f37a-5768b65d001d"
   },
   "outputs": [],
   "source": [
    "# predicting churn with default cut-off 0.5\n",
    "cut_off_prob=0.5\n",
    "y_train_df = predictChurnWithProb(gbm_final,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ornDvDSJw1hd",
    "outputId": "42a75e71-afd2-4ab4-cee7-f8ab6c8de7d5"
   },
   "outputs": [],
   "source": [
    "findOptimalCutoff(y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XG0ExKoxw1he",
    "outputId": "20a67d08-e457-441b-f12a-9bf6ec36f160"
   },
   "outputs": [],
   "source": [
    "cut_off_prob=0.1\n",
    "predictChurnWithProb(gbm_final,X_train_pca,y_train_res,cut_off_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntcj0WR2w1hg"
   },
   "source": [
    "**Making prediction on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOPDN2aUw1hg",
    "outputId": "fa5d5ac5-2901-4b72-d5ac-ca0b8b61e1cc"
   },
   "outputs": [],
   "source": [
    "y_test_df= predictChurnWithProb(gbm_final,X_test_pca,y_test,cut_off_prob)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuHp7i36w1hh"
   },
   "source": [
    "This model is litrally over-fitting the Training data with a lower performance on the Test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JBeT-Tzw1hh"
   },
   "source": [
    "###### 4.2 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZFPY0oQw1hh"
   },
   "source": [
    "##### Applying XGBoost Classifier on our principal components with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HkSvN1sw1hh"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "# Fitting the XGBClassifier\n",
    "xgb1 = XGBClassifier(learning_rate =0.1,\n",
    "                    n_estimators=1000,\n",
    "                    max_depth=5,\n",
    "                    min_child_weight=1,\n",
    "                    gamma=0,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    objective= 'binary:logistic',\n",
    "                    nthread=4,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9X_WCM6w1hi",
    "outputId": "f5375d48-b0f9-441d-9374-a3222d353e0d"
   },
   "outputs": [],
   "source": [
    "# Model fit and performance on Train data\n",
    "modelfit(xgb1, X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gi73Mcd4w1hk",
    "outputId": "2418db17-9d7f-4521-c0fa-919bacaa4d7f"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tunning for the XGBClassifer\n",
    "param_test1 = {'max_depth':range(3,10,2),'min_child_weight':range(1,6,2)}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='f1',n_jobs=4,iid=False, cv=3,return_train_score=True)\n",
    "gsearch1.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu-TYHeXw1hl",
    "outputId": "6aca52dc-327d-460a-9dcc-58bd5db08dbc"
   },
   "outputs": [],
   "source": [
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHsHGa3Bw1hm",
    "outputId": "bec09dfb-bc98-4eb8-ee86-4c9e846ef1fc"
   },
   "outputs": [],
   "source": [
    "# Some more hyperparameter tunning for the XGBClassifer\n",
    "param_test2 = param_test3 = {'gamma':[i/10.0 for i in range(0,5)]}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=9,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='f1',n_jobs=4,iid=False, cv=3,return_train_score=True)\n",
    "gsearch2.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJQyVisSw1hn",
    "outputId": "f744982f-f810-4926-8ff6-d2d41fbd8517"
   },
   "outputs": [],
   "source": [
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hyLzbfpqw1ho"
   },
   "outputs": [],
   "source": [
    "# Final XGBClassifier\n",
    "xgb2 = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=9,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tl6OFgIZw1hp",
    "outputId": "9d3cab8d-92c9-4647-8410-8db9afd8a75b"
   },
   "outputs": [],
   "source": [
    "# Fit Train data\n",
    "modelfit(xgb2, X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YT_WYgBw1hq"
   },
   "outputs": [],
   "source": [
    "# Prediction on Test data\n",
    "dtest_predictions = xgb2.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpZe-DO9w1hs",
    "outputId": "bf190e4b-48c2-43e6-932c-70fa5591625d"
   },
   "outputs": [],
   "source": [
    "# Model evaluation on Test data\n",
    "getModelMetrics(y_test,dtest_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCuUgpxEw1hu"
   },
   "source": [
    "Let's see if we can achive a better Recall rate by deciding an optimal cut-off for the model to predict churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnsdWAGtw1hw",
    "outputId": "b8e69ddb-9bce-42aa-920a-44c540d529a2"
   },
   "outputs": [],
   "source": [
    "# predicting churn with default cut-off 0.5\n",
    "cut_off_prob=0.5\n",
    "y_train_df = predictChurnWithProb(xgb2,X_train_pca,y_train_res,cut_off_prob)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlVSv2Wpw1hx",
    "outputId": "0f7a8baa-28bd-447d-c8b7-5533b7293e4e"
   },
   "outputs": [],
   "source": [
    "# Finding optimal cut-off probability\n",
    "findOptimalCutoff(y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpR60BOxw1h0",
    "outputId": "4f326984-389f-4c69-84d6-52d414747e88"
   },
   "outputs": [],
   "source": [
    "# Selecting 0.2 as cut-off in an attempt to improve recall rate\n",
    "cut_off_prob=0.2\n",
    "predictChurnWithProb(xgb2,X_train_pca,y_train_res,cut_off_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s--K-_Mkw1h1"
   },
   "source": [
    "**Making prediction on test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cipaXKfPw1h1",
    "outputId": "6b01f524-b547-46d5-b536-8ee3300326ff"
   },
   "outputs": [],
   "source": [
    "y_test_df= predictChurnWithProb(xgb2,X_test_pca,y_test,cut_off_prob)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5kKREtHw1h3"
   },
   "source": [
    "### 5. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZnmP7ksw1h3"
   },
   "source": [
    "##### Using linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TB1Mw0Mdw1h4"
   },
   "outputs": [],
   "source": [
    "# instantiate an object of class SVC()\n",
    "# note that we are using cost C=1\n",
    "svm0 = SVC(C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SV9AinIjw1h5",
    "outputId": "bdc8a09a-11ef-4c14-82cc-97df6bffacae"
   },
   "outputs": [],
   "source": [
    "# fit\n",
    "svm0.fit(X_train_pca, y_train_res)\n",
    "\n",
    "# predict on train\n",
    "y_pred = svm0.predict(X_train_pca)\n",
    "getModelMetrics(y_train_res,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrEP4D8Tw1h6",
    "outputId": "ac12b6b1-29b1-4f38-b069-3574fb7650e3"
   },
   "outputs": [],
   "source": [
    "# Predict on test\n",
    "y_pred = svm0.predict(X_test_pca)\n",
    "getModelMetrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKNeHW7Cw1h7"
   },
   "source": [
    "###### Hyperparameter tuning for linear kernal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fmP1sCxw1h7"
   },
   "source": [
    "Let's see if we can tune the hyperparameters of SVM and get a better Sensitivity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHU-DFGQw1h8",
    "outputId": "75d3fb62-7696-49d3-aac1-6a7030e8c141"
   },
   "outputs": [],
   "source": [
    "# specify range of parameters (C) as a list\n",
    "params = {\"C\": [0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "svm1 = SVC()\n",
    "\n",
    "# set up grid search scheme\n",
    "# note that we are still using the 5 fold CV scheme\n",
    "model_cv = GridSearchCV(estimator = svm1, param_grid = params, \n",
    "                        scoring= 'f1', \n",
    "                        cv = 5, \n",
    "                        verbose = 1,\n",
    "                        n_jobs=4,\n",
    "                       return_train_score=True) \n",
    "model_cv.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKRowxDuw1h-",
    "outputId": "fb0155f5-31de-4696-8a91-f0cf3cc526e3"
   },
   "outputs": [],
   "source": [
    "plot_traintestAcc(model_cv.cv_results_,'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJCGbE0zw1h_",
    "outputId": "348130e2-1ea7-430b-a2ac-7f6d38388fb3"
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-en-z_b7w1iB"
   },
   "outputs": [],
   "source": [
    "svm_final = SVC(C = 1000)\n",
    "# fit\n",
    "svm_final.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_klL-Nq2w1iC"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = svm_final.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exo6oS-nw1iC",
    "outputId": "090bf73c-9898-4df8-e3b4-0c949254d573"
   },
   "outputs": [],
   "source": [
    "getModelMetrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O60K8t3tw1iD"
   },
   "source": [
    "##### Using non-linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzr6ijfKw1iE",
    "outputId": "336f12f1-2b56-4a1e-ba8e-f88f16702b35"
   },
   "outputs": [],
   "source": [
    "svm_k = SVC(C = 1000, kernel='rbf')\n",
    "svm_k.fit(X_train_pca, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7H7QnrTw1iF"
   },
   "outputs": [],
   "source": [
    "y_pred = svm_k.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_ZzLloNw1iG",
    "outputId": "f13ce8d8-2471-4e83-bc86-00f9fd9f7a76"
   },
   "outputs": [],
   "source": [
    "getModelMetrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yD3zBmNlw1iI"
   },
   "source": [
    "**Recall Score: 78%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-AHANYiw1iI"
   },
   "source": [
    "Now that we have a variety of models used to predict the churn for the telecom. Let's caompare and decide a model of choice for this problem of churn prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAK656wEw1iJ"
   },
   "source": [
    "## Final Choice of Model \n",
    "\n",
    "Recall is the most important business metric for the telecom churn problem. The company would like to identify most customers at risk of churning, even if there are many customers that are misclassified as churn. The cost to the company of churning is much higher than having a few false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9qJEWQXw1iJ"
   },
   "source": [
    "| Model/Metrics                         | Train   | Test   |\n",
    "|---------------------------------------|---------|--------|\n",
    "| Logistic Regression ( cut-off = 0.45) |         |        |\n",
    "| Roc_auc_score                         | 82.11%  | 81.21% |\n",
    "| Sensitivity/Recall                    | 86.48%  | 84.40% |\n",
    "| Specificity                           | 77.75%  | 78.02% |\n",
    "| precision                             | 79.54%  | 25.04% |\n",
    "| DecisionTree ( cut-off = 0.4)         |         |        |\n",
    "| Roc_auc_score                         | 82.41%  | 76.57% |\n",
    "| Sensitivity/Recall                    | 89.79%  | 78.13% |\n",
    "| Specificity                           | 75.03%  | 75%    |\n",
    "| precision                             | 78.24%  | 21.38% |\n",
    "| Random Forest (cut-off = 0.45)        |         |        |\n",
    "| Roc_auc_score                         | 85.60%  | 96.53% |\n",
    "| Sensitivity/Recall                    | 88.70%  | 77.57% |\n",
    "| Specificity                           | 82.50%  | 81.73% |\n",
    "| precision                             | 83.52%  | 26.97% |\n",
    "| GBC                                   |         |        |\n",
    "| Roc_auc_score                         | 96.11%  | 80.84% |\n",
    "| Sensitivity/Recall                    | 100.00% | 79.87% |\n",
    "| Specificity                           | 92.21%  | 81.81% |\n",
    "| precision                             | 92.78%  | 28.52% |\n",
    "| XGB (cut-off = 0.2)                   |         |        |\n",
    "| Roc_auc_score                         | 97.24%  | 80.76% |\n",
    "| Sensitivity/Recall                    | 99.99%  | 76.13% |\n",
    "| Specificity                           | 94.49%  | 85.38% |\n",
    "| precision                             | 94.78%  | 32.13% |\n",
    "| SVM (linear   C = 1000 )              |         |        |\n",
    "| Roc_auc_score                         | 81.33%  | 82.62% |\n",
    "| Sensitivity/Recall                    | 79.91%  | 78.40% |\n",
    "| Specificity                           | 82.75%  | 86.85% |\n",
    "| precision                             | 82.25%  | 35.14% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyCaUjSow1iJ"
   },
   "source": [
    "Overall, the **Logistic Regression** model with probability cut-off = 0.45, performs best. It achieved the **best recall accuracy of 84.4%** for test data. Also the overall accuracy and specificity is consistent for Test and train data, thus avoiding overfitting. The precision is compromised in this effort but the business objective to predict Churn customers is most accuratety captured by it. \n",
    "\n",
    "Next, Linear SVM which achives a recall rate of 78.40%, a slightly better precision of 35.14% and a balanced overall accuracy on train and test.\n",
    "\n",
    "From the Tree Family, the Decision Tree overfitted the data slightly while obtaining 78.13% recall accuracy on test data. \n",
    "The Random Forest avoided overfitting but obtained only 77.57% recall accuracy on test data. \n",
    "\n",
    "Among the Bossting Methods, Gradient Boosting Classifer (GBC) achived 81.81% recall rate and XGBoost Classifier achived 76.13% but both tend to overfit the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjB3mj5Qw1iJ"
   },
   "source": [
    "## Identifying relevant churn features. \n",
    "\n",
    "We will use an instance of Random Forest classifier to identify the features most relevant to churn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1gKFJ0Pw1iK"
   },
   "source": [
    "### Random Forest for churn driver features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-An6owuw1iK"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [8,10,12],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [12, 15, 20]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 4,verbose = 1,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0ZaPxKWw1iL",
    "outputId": "4313ac4b-798e-4f3b-80ca-969f5bafeb4e"
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BicPUvQvw1iM",
    "outputId": "f05aa565-4af4-4c33-b275-b68de75a4f7e"
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgyYzKN-w1iN"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=12,\n",
    "                            max_features=20,\n",
    "                            min_samples_leaf=100,\n",
    "                            min_samples_split=200,\n",
    "                            n_estimators=300,\n",
    "                            random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12m0Ky7Qw1iO",
    "outputId": "7ff28b8f-5225-4494-f9ee-f8f9a3f4a660"
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sOxrWn1fw1iO",
    "outputId": "ff32dfc1-25ee-4cfd-ee4c-c5b7d9f0f98b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,40))\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(len(X.columns)).sort_values().plot(kind='barh', align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oo9x6mxlyBr0"
   },
   "source": [
    "Some of the top main predictiors of churn are the monthly KPI features for the action phase (3rd month August)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "voAggfHWw1iP"
   },
   "source": [
    "the graph above suggest that the top 25 features ranked in order of importance as produced by our RandomForest implementation are the features that belong to month 8 i.e., the action month. Hence, it is clear that what happens in the action phase has a direct impact on the customer churn of high value customers. Specifically, these features are as follows:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.\t**total_ic_mou_8**\t\t-- *Total incoming minutes of usage in month 8*\n",
    "2.\t**loc_ic_mou_8**\t\t-- *local incoming minutes of usage in month 8*\n",
    "3.\t**total_month_rech_8**\t-- *Total month recharge amount in month 8*\t\n",
    "4.\t**total_roam_mou_8**\t-- *Total incoming+outgoing roaming minutes of usage in month 8*\n",
    "5.\t**loc_ic_t2m_mou_8**\t-- *local incoming calls to another operator minutes of usage in month 8*\n",
    "6.\t**roam_og_mou_8**\t\t-- *outgoing roaming calls minutes of usage in month 8*\n",
    "7.\t**Total_loc_mou_8**\t\t-- *Total local minutes of usage in month 8*\n",
    "8.\t**roam_ic_mou_8**\t\t-- *incoming roaming calls minutes of usage in month 8*\n",
    "9.\t**total_rech_amt_8**\t-- *total recharge amount in month 8*\n",
    "10.\t**loc_ic_t2t_mou_8**\t-- *local incoming calls from same operator minutes of usage in month 8*\n",
    "11.\t**max_rech_amt_8**\t\t-- *maximum recharge amount in month 8*\n",
    "12.\t**last_day_rch_amt_8**\t-- *last (most recent) recharge amount in month 8*\n",
    "13.\t**arpu_8**\t\t\t\t-- *average revenue per user in month 8*\n",
    "14.\t**loc_og_mou_8**\t\t-- *local outgoing calls minutes of usage in month 8*\n",
    "15.\t**loc_og_t2n_mou_8**\t-- *local outgoing calls minutes of usage to other operator mobile in month 8*\n",
    "16.\t**av_rech_amt_data_8**\t-- *average recharge amount for mobile data in month 8*\n",
    "17.\t**total_rech_data_8**\t-- *total data recharge (MB) in month 8*\n",
    "18.\t**total_og_t2t_mou_8**\t-- *total outgoing calls from same operator minutes of usage in month 8*\n",
    "19.\t**total_rech_num_8**\t-- *total number of recharges done in the month 8*\n",
    "20.\t**total_rech_amt_data_8**\t-- *total recharge amount for data in month 8*\n",
    "21.\t**max_rech_data_8**\t\t-- *maximum data recharge (MB) in month 8*\n",
    "22.\t**avg_rech_amt_8**\t\t-- *average recharge amount in month 8*\n",
    "23.\t**fb_user_8**\t\t\t-- *services of Facebook and similar social networking sites for month 8*\n",
    "24.\t**vol_data_mb_8**\t\t-- *volume of data (MB) consumed for month 8*\n",
    "25.\t**count_rech_2g_8**\t\t-- *Number of 2g data recharge in month 8*\n",
    "26.\t**loc_og_to_ic_mou_8**\t-- *local outgoing to incoming mou ratio for month of 8*\n",
    "27.\t**spl_og_mou_7**\t\t-- *Special outgoing call for the month of 7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local calls Mou's be it incoming or outgoing have a very important role for churn predictions. Reduction in these KPI's forms a clear indicator of churn.\n",
    "\n",
    "Overall, drop in any of these indicator KPI is a signal that the customer is not actively engaging in the services offered by the Network operator and thus may choose to churn in the near future.\n",
    "\n",
    "Next, we will look at some of the stratergic steps which can be taken to retain these predicted churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99pwzPygw1iU"
   },
   "source": [
    "## Strategies to manage customer churn\n",
    "\n",
    "It is a fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring Drop in usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer churn seems to be well predicted by drop in usage. \n",
    "\n",
    "Aside from using the Machine Learning model for predicting churn, the telecom company should pay close attention to drop in MoU, ARPU and data usage (2g and 3g) month over month. If feasible, the company should track these numbers week over week. Since billing cycles are typically monthly, a drop in usage numbers will give the company time to react when tracked at weekly level. \n",
    "\n",
    "Contact these customers proactively to find out what's affecting their experience. Perhaps, offer them coupons or other incentives to continue to use the services, while the company fixes the issues reported. \n",
    "\n",
    "Marketing team must come up with campaigns which targets these high-value to-be churner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieeViNBBw1iU"
   },
   "source": [
    "#### Improving Outgoing services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlVV0xEGw1iU",
    "outputId": "66db73b2-7d0a-43c7-992f-fa2334fe3b3b"
   },
   "outputs": [],
   "source": [
    "# Outgoing Mou\n",
    "plot_byChurnMou(og_col,'Outgoing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bp5tVLdiw1iW"
   },
   "source": [
    "-  Initially, churner's outgoing usage was more than that of non-churners. Gradually they dropped there outgoing usage. May be these customers din't like the outgoing services offered to them or may be the call tariffs seemed expensive to them or may be the overall call quality, network coverage was not liked my them. This could be further investigated by the network service provider. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wejnqwYCw1iW"
   },
   "source": [
    "Stratergy suggestions,\n",
    "- The Network operators must futher investigate their outgoing tariffs, plans and campaigns.\n",
    "- Might be that the outgoing tariffs offered to it's customer are less competitive to the outgoing tariffs of their competitor.\n",
    "- New campaigns which targets the customers with high outgoing usage be rolled out.Like, \n",
    "    - Discounted outgoing rates during particular hours of the day for these customers.\n",
    "    - For every X mou, grant customer with some % of X free mou.\n",
    "    - Investigate and if need be revise the outgoing tarrifs to make it competitive.\n",
    "    - Free monthly outgoing mou's depending on the users past roaming mou usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAA_AXYXw1iW"
   },
   "source": [
    "#### Improving Roaming services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ht1El62w1iY",
    "outputId": "5ed3b021-637d-4418-c746-3697fb0138f6"
   },
   "outputs": [],
   "source": [
    "plot_byChurn(hv_users,'Total_roam_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AlbyM6gw1ia"
   },
   "source": [
    "Stratergy suggestions,\n",
    "- Churners show higher roaming usage than non-churners.\n",
    "- The Network operators must futher investigate their roaming tariffs, and quality of service.\n",
    "- Might be that the roaming tariffs offered are less competitive than their competitor.\n",
    "- It might be that the customer is not getting good quality of service while roaming. In this case, quality of service guarantees with roaming partners and network quality need to be investigated.\n",
    "- New campaigns which targets the roaming customers can be rolled out. Like, \n",
    "    - Discounted roaming rates during particular hours of the day.\n",
    "    - Free monthly roaming mou's depending on the users past roaming mou usage."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qFQpGLvaw1d0",
    "o7WGRV_Hw1gN",
    "wUZpKshPw1gQ",
    "ibcAPYP7w1gr",
    "T3Aa5rJsw1gt",
    "K9WuZSfww1g2",
    "t7YVGrqKw1g5",
    "ak4zK8ORw1g8",
    "vCPOdDG7w1hC",
    "yc7S_S7-w1hE",
    "n40kKPV5w1hP",
    "G5kKREtHw1h3",
    "ZAK656wEw1iJ",
    "99pwzPygw1iU"
   ],
   "name": "Akshay_Final_Submission_Telecom Churn - ML Group Case Study.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
